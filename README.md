# README â€” Ã‰tape 1
IntÃ©gration et transformation de donnÃ©es mÃ©tÃ©orologiques (Forecast 2.0)
Projet : GreenAndCoop â€“ Forecast 2.0

RÃ´le : Data Engineer
Objectif de lâ€™Ã©tape 1 :
Mettre en place un premier pipeline permettant de collecter, transformer, tester et stocker des donnÃ©es mÃ©tÃ©orologiques issues de diffÃ©rentes sources dans Amazon S3, dans un format compatible avec une future intÃ©gration dans MongoDB.

## 1. Contexte du projet

Dans le cadre du projet Forecast 2.0, lâ€™entreprise GreenAndCoop souhaite enrichir ses modÃ¨les de prÃ©vision de la demande Ã©lectrique avec de nouvelles sources de donnÃ©es mÃ©tÃ©orologiques, notamment :

Des stations semi-professionnelles du rÃ©seau InfoClimat

Des stations amateurs du rÃ©seau Weather Underground (France et Belgique)

Ces sources prÃ©sentent :

des formats hÃ©tÃ©rogÃ¨nes (JSON, Excel)

des frÃ©quences diffÃ©rentes

des mÃ©tadonnÃ©es variables

Le rÃ´le du Data Engineer est de construire un pipeline fiable permettant de fournir des donnÃ©es propres, cohÃ©rentes et exploitables par les Data Scientists.

## 2. Architecture de lâ€™Ã©tape 1

Vue dâ€™ensemble

```java
Sources mÃ©tÃ©o
   â”‚
   â–¼
Airbyte
   â”‚
   â–¼
Amazon S3 (zone RAW)
   â”‚
   â–¼
Scripts Python (transformation + tests)
   â”‚
   â–¼
Amazon S3 (zone PROCESSED, format MongoDB-ready)
```
Structure S3 utilisÃ©e

```pgsql
s3://p8-meteo/
â”‚
â”œâ”€â”€ p8-data-path/                # DonnÃ©es brutes (Airbyte)
â”‚   â”œâ”€â”€ InfoClimat_data/
â”‚   â”œâ”€â”€ France_data/
â”‚   â””â”€â”€ Belgique_data/
â”‚
â””â”€â”€ p8-processed/                # DonnÃ©es transformÃ©es
    â”œâ”€â”€ weather_mongodb_ready.json
    â””â”€â”€ quality_report.json
```


## 3. Collecte des donnÃ©es (Airbyte)

La collecte est rÃ©alisÃ©e avec Airbyte, qui permet de :

se connecter aux diffÃ©rentes sources mÃ©tÃ©o

uniformiser lâ€™extraction

stocker les donnÃ©es brutes dans Amazon S3

Les donnÃ©es sont exportÃ©es au format JSONL dans un bucket S3.

ğŸ‘‰ Aucune transformation nâ€™est faite dans Airbyte
Toute la logique mÃ©tier est volontairement gÃ©rÃ©e cÃ´tÃ© Python.


### 3.1 Installation et configuration dâ€™Airbyte

PrÃ©requis :

Docker Desktop installÃ© et en fonctionnement

Terminal (PowerShell, CMD ou bash)

Installation Airbyte via Docker

Suivre les Ã©tapes de la documentation officiel:
https://docs.airbyte.com/platform/using-airbyte/getting-started/oss-quickstart

AccÃ©der Ã  Airbyte :
Ouvrir un navigateur â†’ http://localhost:8000


### 3.2 PrÃ©paration AWS

#### 3.2.1 CrÃ©ation dâ€™un bucket S3

Connectez-vous Ã  votre console AWS.

Allez dans S3 â†’ Create bucket

Donnez un nom unique, ex : p8-meteo

Configurez la rÃ©gion (ex : eu-west-3)

Laissez les autres paramÃ¨tres par dÃ©faut â†’ Create bucket


#### 3.2.2 CrÃ©ation dâ€™un utilisateur IAM pour Airbyte

Aller dans IAM â†’ Users â†’ Add user

Nom : airbyte-s3-user

AccÃ¨s programmatique â†’ cochez Programmatic access

Attachez la policy AmazonS3FullAccess

Cliquez sur Create user

RÃ©cupÃ©rez :

AWS_ACCESS_KEY_ID

AWS_SECRET_ACCESS_KEY

âš ï¸ Important : Conservez-les prÃ©cieusement, ne les mettez pas dans Git.


### 3.3 Connexion Airbyte â†’ AWS S3 (Destination)

Dans Airbyte :

Ajouter une destination

Type : Amazon S3

Renseignez :

Access Key ID â†’ AWS_ACCESS_KEY_ID

Secret Access Key â†’ AWS_SECRET_ACCESS_KEY

Bucket Name â†’ p8-meteo

Region â†’ eu-west-3

Testez la connexion â†’ Save


### 3.4 Configuration Airbyte

DÃ©finition des sources et de la destination dans Airbyte

#### 3.4.1 DÃ©finir les sources mÃ©tÃ©o

Dans Airbyte :

Ajouter une source â†’ choisir le connecteur correspondant :

InfoClimat : JSON depuis API ou fichiers bruts

Weather Underground : Excel ou API selon le setup

Renseigner les paramÃ¨tres spÃ©cifiques Ã  chaque source :

Nom de la source (ex : InfoClimat_FR)

Chemin dâ€™accÃ¨s ou URL

FrÃ©quence de synchronisation

Tester la connexion â†’ Save

RÃ©pÃ©tez pour toutes les sources (InfoClimat, France_data, Belgique_data).


#### 3.4.2 DÃ©finir la destination S3

Ajouter une destination â†’ choisir Amazon S3

ParamÃ¨tres Ã  remplir :

AWS Access Key ID â†’ AWS_ACCESS_KEY_ID

AWS Secret Access Key â†’ AWS_SECRET_ACCESS_KEY

Bucket Name â†’ p8-meteo

Region â†’ eu-west-3

Format â†’ JSONL

Tester la connexion â†’ Save


#### 3.4.3 CrÃ©er la connexion (Sync) Airbyte

Aller dans Connections â†’ New connection

SÃ©lectionner :

Source â†’ la source mÃ©tÃ©o dÃ©finie

Destination â†’ Amazon S3

Configurer :

FrÃ©quence â†’ Ex. Every hour ou Manual

Mode de chargement â†’ Overwrite ou Append selon le besoin

Tester â†’ Save â†’ Sync now

Les donnÃ©es brutes de chaque source seront automatiquement stockÃ©es dans S3 (p8-data-path/â€¦) en JSONL, prÃªtes pour la transformation Python.


## 4. Transformation des donnÃ©es (S3 â†’ S3)
Objectif

Transformer les donnÃ©es brutes en documents JSON compatibles MongoDB, avec :

un schÃ©ma commun entre toutes les sources

la conservation maximale des informations

une structure facilement requÃªtable

SchÃ©ma cible (logique)
```json
{
  "source": "weather_underground | infoclimat",
  "station": { ... },
  "timestamp": "ISO-8601",
  "measurements": { ... }
}
```

Points techniques importants
Weather Underground

Les fichiers Excel contenaient une feuille par jour

La date nâ€™est pas conservÃ©e par Airbyte

Les donnÃ©es sont ordonnÃ©es par heure (Time)

ğŸ‘‰ La date est reconstruite en dÃ©tectant le retour Ã  00:xx:xx, ce qui indique un changement de jour.

InfoClimat

Les mÃ©tadonnÃ©es des stations sont extraites et intÃ©grÃ©es

Toutes les mesures disponibles sont conservÃ©es (tempÃ©rature, pression, pluie, neige, vent, etc.)

Les valeurs manquantes sont gÃ©rÃ©es explicitement (None ou 0 selon le cas)



## 5. ContrÃ´le qualitÃ© des donnÃ©es

Un script dÃ©diÃ© permet de mesurer la qualitÃ© des donnÃ©es aprÃ¨s transformation :

VÃ©rifications effectuÃ©es

PrÃ©sence de valeurs manquantes critiques (tempÃ©rature)

DÃ©tection de doublons (station_id + timestamp)

Calcul dâ€™un taux dâ€™erreur global

```yaml
RÃ©sultat obtenu
Total records        : 4950
Valeurs manquantes   : 0
Doublons             : 0
Taux dâ€™erreur        : 0.0 %
```

Ces rÃ©sultats garantissent que les donnÃ©es sont prÃªtes pour une intÃ©gration en base NoSQL.


## 6. PrÃ©requis techniques

Environnement

Windows

Python â‰¥ 3.9

Compte AWS actif

Docker Desktop installÃ© (utilisÃ© dans les Ã©tapes suivantes)


## 7. Configuration AWS

Installation de lâ€™AWS CLI

TÃ©lÃ©charger et installer lâ€™AWS CLI depuis :
https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html

Configuration des credentials

Dans un terminal PowerShell :
```bash
aws configure
```

Renseigner :
```bash
AWS Access Key ID

AWS Secret Access Key

Default region name (ex : eu-west-3)

Default output format : json
```

VÃ©rification
```bash
aws s3 ls
```

Le bucket p8-meteo doit apparaÃ®tre.


## 8. DÃ©pendances Python

requirements.txt
```bash
boto3==1.42.19
python-dateutil==2.9.0
```

Installation

Avec un environnement virtuel (recommandÃ©) :

```bash
pip install -r requirements.txt
```


## 9. ExÃ©cution des scripts

Transformation des donnÃ©es
```bash
python transform_weather_s3.py
```

RÃ©sultat :
```bash
p8-processed/weather_mongodb_ready.json
```

Tests de qualitÃ©
```bash
python data_quality_checks_s3.py
```

RÃ©sultat :
```bash
p8-processed/quality_report.json
```


## 10. Conclusion de lâ€™Ã©tape 1

Ã€ lâ€™issue de cette Ã©tape :

Les donnÃ©es sont centralisÃ©es dans S3

Elles sont nettoyÃ©es, structurÃ©es et enrichies

Leur qualitÃ© est mesurÃ©e et validÃ©e

Le format est directement compatible MongoDB

ğŸ‘‰ Le pipeline est prÃªt pour lâ€™Ã‰tape 2 : intÃ©gration dans MongoDB, mise en place du schÃ©ma et des collections.


# Ã‰TAPE 2 â€” Migration des donnÃ©es vers MongoDB

## 1ğŸ¯ Objectif de lâ€™Ã©tape

Cette Ã©tape consiste Ã  importer les donnÃ©es mÃ©tÃ©orologiques prÃ©alablement transformÃ©es (Ã‰tape 1) depuis Amazon S3 vers une base de donnÃ©es MongoDB, tout en :

respectant un schÃ©ma commun pour toutes les sources,

assurant la qualitÃ© et lâ€™intÃ©gritÃ© des donnÃ©es post-migration,

mettant en place des contrÃ´les automatiques,

documentant clairement le processus.


## 2ğŸ§± Architecture retenue

Source des donnÃ©es :
Amazon S3
s3://p8-meteo/p8-processed/weather_mongodb_ready.json

Base de donnÃ©es :
MongoDB en local (Docker / MongoDB Community)

Nom de la base :
p8_greenandcoop_forecast

Collection unique :
weather_data

ğŸ‘‰ Le choix dâ€™une seule collection permet :

dâ€™unifier les requÃªtes,

de faciliter lâ€™agrÃ©gation multi-sources,

de garantir un schÃ©ma homogÃ¨ne.


## 3ğŸ“„ Format des donnÃ©es importÃ©es

Les donnÃ©es sont stockÃ©es dans un fichier JSON compatible MongoDB, contenant une liste de documents standardisÃ©s.

Structure logique dâ€™un document :
{
  "source": "weather_underground | infoclimat",
  "station": {
    "station_id": "string",
    "name": "string",
    "latitude": float,
    "longitude": float,
    "elevation": int
  },
  "timestamp": "ISO-8601",
  "measurements": {
    "temperature_c": float,
    "humidity_pct": float,
    "pressure_hpa": float,
    "wind_speed": float,
    "wind_gust": float,
    "precip_mm": float
  }
}


Ce schÃ©ma est identique pour toutes les sources, conformÃ©ment aux exigences du projet.


## 4ğŸ” Processus suivi (logigramme)

Le processus a Ã©tÃ© formalisÃ© sous forme de logigramme visuel, basÃ© sur les Ã©tapes suivantes :

- DÃ©finir sources mÃ©tÃ©o dans Airbyte (Ã©tape 1)

- DÃ©finir destination S3 dans Airbyte (Ã©tape 1)

- CrÃ©er la connexion (Sync) Airbyte (Ã©tape 1)

- Airbyte collecte les donnÃ©es â†’ Stockage dans S3 (Ã©tape 1)

- Lecture du fichier JSON depuis S3

- Chargement des documents en mÃ©moire

- Connexion Ã  MongoDB

- Insertion des documents dans la collection

- VÃ©rifications post-import :

nombre total de documents,

doublons,

valeurs manquantes sur champs critiques

- Affichage des rÃ©sultats en console


## 5 ğŸ§ª ContrÃ´les qualitÃ© post-migration

AprÃ¨s lâ€™import, le script exÃ©cute automatiquement plusieurs contrÃ´les :

âœ”ï¸ Indicateurs mesurÃ©s

Nombre total de documents importÃ©s

Nombre de doublons (station_id + timestamp)

Nombre de documents sans :

tempÃ©rature

humiditÃ©

pression

âœ”ï¸ RÃ©sultat obtenu
Total documents en base : 4950
Nombre de doublons dÃ©tectÃ©s : 0
Documents sans tempÃ©rature : 0
Documents sans humiditÃ© : 0
Documents sans pression : 0


ğŸ‘‰ Ces rÃ©sultats confirment :

lâ€™intÃ©gritÃ© du schÃ©ma,

lâ€™absence de perte de donnÃ©es,

une migration fiable.


## 6 ğŸ Script utilisÃ©

Un script Python unique est utilisÃ© pour :

rÃ©cupÃ©rer le fichier depuis S3,

importer les donnÃ©es dans MongoDB,

exÃ©cuter les contrÃ´les qualitÃ©,

afficher les rÃ©sultats via des print() explicites.

Script principal
import_s3_to_mongodb.py


## 7 â–¶ï¸ ExÃ©cution du script

### 1ï¸âƒ£ PrÃ©-requis

MongoDB lancÃ© en local (Docker ou service local)

AccÃ¨s AWS configurÃ©

Environnement Python actif

ğŸ“¦ DÃ©pendances Python

Installer pymongo avec la version dans requirements.txt

Le fichier requirements.txt inclut notamment :

boto3==1.42.19
python-dateutil==2.9.0
pymongo==4.15.4


ğŸ‘‰ pymongo est utilisÃ© pour la communication avec MongoDB
ğŸ‘‰ boto3 permet lâ€™accÃ¨s aux objets stockÃ©s sur S3

### 2ï¸âƒ£ Commande dâ€™exÃ©cution
python import_s3_to_mongodb.py

### 3ï¸âƒ£ RÃ©sultat attendu en console
RÃ©cupÃ©ration du fichier depuis S3...
Nombre de documents Ã  importer : 4950
Documents importÃ©s avec succÃ¨s : 4950

--- VÃ©rification post-import ---
Total documents en base : 4950
Nombre de doublons dÃ©tectÃ©s : 0
Documents sans tempÃ©rature : 0
Documents sans humiditÃ© : 0
Documents sans pression : 0

--- Import terminÃ© ---


## 8 ğŸ” Visualisation des donnÃ©es

Les donnÃ©es peuvent Ãªtre visualisÃ©es avec MongoDB Compass :

Base : p8_greenandcoop_forecast

Collection : weather_data

RÃ©partition observÃ©e :

Infoclimat : 1143 documents

Weather Underground (France + Belgique) : 3807 documents


# Ã‰TAPE 3

Conteneurisation de la migration avec Docker

## 1 ğŸ¯ Objectif de lâ€™Ã©tape 3

Lâ€™objectif de cette Ã©tape est de conteneuriser la migration des donnÃ©es mÃ©tÃ©o depuis Amazon S3 vers MongoDB, afin de :

- garantir la reproductibilitÃ© de lâ€™environnement,

- isoler les composants (base de donnÃ©es / script de migration),

- persister les donnÃ©es via un volume Docker,

- dÃ©montrer une migration automatisÃ©e et fiable.


## 2 ğŸ—ï¸ Architecture mise en place

- 1 conteneur MongoDB
  - Image officielle mongo:7.0
  - DonnÃ©es persistÃ©es via un volume Docker

- 1 conteneur Python
  - ExÃ©cute un script de migration
  - TÃ©lÃ©charge les donnÃ©es depuis S3
  - InsÃ¨re les documents dans MongoDB
  - Effectue des contrÃ´les qualitÃ© post-import

Les deux conteneurs communiquent via le rÃ©seau Docker Compose par dÃ©faut.


## 3 ğŸ“ Structure du projet (Ã©tape 3)

```bash
.
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â”œâ”€â”€ import_s3_to_mongodb_conteneur.py
```

## 4 âš™ï¸ Configuration des variables dâ€™environnement

Le fichier .env (non versionnÃ©) contient :

```env
AWS_ACCESS_KEY_ID=************
AWS_SECRET_ACCESS_KEY=************
AWS_DEFAULT_REGION=eu-west-3

MONGO_URI=mongodb://mongodb:27017
```

- Les credentials AWS permettent lâ€™accÃ¨s au bucket S3

- mongodb correspond au nom du service Docker MongoDB


## 5 ğŸ³ docker-compose.yml (rÃ©sumÃ©)

- MongoDB exposÃ© sur le port local 27021

- Volume Docker pour persister les donnÃ©es

- Conteneur Python dÃ©pendant de MongoDB

MongoDB reste accessible depuis lâ€™hÃ´te via MongoDB Compass :

```bash
mongodb://localhost:27021
```

## 6 ğŸ“¦ Volume Docker

Un volume nommÃ© est utilisÃ© :

```bash
projet8_projet_8_mongo_data
```

Il garantit que les donnÃ©es MongoDB sont conservÃ©es mÃªme aprÃ¨s :

```bash
docker compose down
```

## 7 ğŸ§  Script de migration

Le script import_s3_to_mongodb_conteneur.py effectue :

- 1) Connexion Ã  Amazon S3

- 2) TÃ©lÃ©chargement du fichier JSON final :

```bash
p8-meteo/p8-processed/weather_mongodb_ready.json
```

- 3) Insertion des documents dans MongoDB

- 4) ContrÃ´les qualitÃ© post-import :
  - Nombre total de documents
  - Doublons (station_id + timestamp)
  - champs critiques manquants (tempÃ©rature, humiditÃ©, pression)


## 8 â–¶ï¸ Commandes Ã  exÃ©cuter
ğŸ”¹ Build + lancement complet initial
```bash
docker compose up --build
```
ğŸ”¹ Lancement sans rebuild
```bash
docker compose up
```
ğŸ”¹ ArrÃªt des services
```bash
docker compose down
```
ğŸ”¹ VÃ©rifier les volumes
```bash
docker volume ls
```
ğŸ”¹ VÃ©rifier les conteneurs
```bash
docker ps -a
```
ğŸ”¹ Inspecter un volume en particulier :
```bash
docker volume inspect projet_8_mongo_data
```

## 9 ğŸ” VÃ©rifications attendues

Logs affichant :

```bash
Documents importÃ©s avec succÃ¨s : 4950
```

MongoDB Compass :

- Base : p8_greenandcoop_forecast

- Collection : weather_data

- 4950 documents prÃ©sents

DonnÃ©es toujours prÃ©sentes aprÃ¨s redÃ©marrage


## 10 âœ… RÃ©sultat

Migration automatisÃ©e et reproductible

Environnement isolÃ© via Docker

DonnÃ©es persistÃ©es

QualitÃ© des donnÃ©es contrÃ´lÃ©e

ğŸ‘‰ Cette Ã©tape valide la conteneurisation complÃ¨te de la chaÃ®ne de migration.



# ğŸš€ Ã‰tape 4 â€” DÃ©ploiement MongoDB sur AWS ECS, reporting et sauvegardes

## 1 ğŸ¯ Objectif de lâ€™Ã©tape

Lâ€™objectif de cette Ã©tape est de dÃ©ployer la base de donnÃ©es MongoDB dans le cloud AWS afin de :

- reproduire lâ€™architecture de migration dans un environnement distant,

- rendre la base accessible Ã  distance de maniÃ¨re sÃ©curisÃ©e,

- importer les donnÃ©es mÃ©tÃ©o depuis Amazon S3 (source de vÃ©ritÃ©),

- mesurer les performances dâ€™accÃ¨s aux donnÃ©es,

- mettre en place une stratÃ©gie de sauvegarde,

- assurer la supervision via des logs centralisÃ©s.

Cette Ã©tape valide la capacitÃ© Ã  industrialiser la chaÃ®ne data dans un environnement cloud.


## 2 ğŸ§± Contexte et prÃ©requis

Ã€ lâ€™issue de lâ€™Ã‰tape 3 :

Les donnÃ©es mÃ©tÃ©o (â‰ˆ 4950 documents) sont :

- collectÃ©es via Airbyte,

- transformÃ©es,

- stockÃ©es dans Amazon S3.

Le fichier final utilisÃ© est :
```bash
s3://p8-meteo/p8-processed/weather_mongodb_ready.json
```

MongoDB fonctionne et est maÃ®trisÃ© :

- en local,

- en environnement Docker.

Lâ€™import S3 â†’ MongoDB est automatisÃ© via un script Python.

ğŸ‘‰ Lâ€™Ã‰tape 4 consiste Ã  transposer cette architecture vers AWS, sans modifier la logique data.


## 3 ğŸ— Architecture cible

Architecture dÃ©ployÃ©e :

```sql
[Poste local]
     |
     | (script Python)
     v
[S3 - p8-meteo]
     |
     v
[MongoDB conteneurisÃ© sur ECS Fargate]
     |
     +--> CloudWatch Logs
     |
     +--> Sauvegardes MongoDB vers S3
```

Choix techniques :

Amazon ECS Fargate : exÃ©cution de conteneurs sans gestion dâ€™instances EC2

MongoDB officiel (mongo:7.0) : cohÃ©rence avec les Ã©tapes prÃ©cÃ©dentes

S3 :

- stockage des donnÃ©es sources,

- stockage des sauvegardes


## ğŸ§© Phase 1 â€” CrÃ©ation de lâ€™infrastructure AWS

## 4 â˜ï¸ Infrastructure AWS mise en place
### 4.1 RÃ©gion AWS

RÃ©gion utilisÃ©e :
```bash
eu-west-3 (Paris)
```

Justification :

- cohÃ©rence avec les buckets S3,

- faible latence,

- conformitÃ© RGPD.

âš ï¸ Les rÃ©gions utilisÃ©es par Airbyte ou S3 nâ€™impactent pas ECS tant que les permissions IAM sont correctes.


## 4.2ï¸ CrÃ©ation du cluster ECS

Mode pas-Ã -pas :

- Connecte-toi Ã  la console AWS â†’ Recherche ECS â†’ Clique sur Clusters â†’ Create Cluster

- SÃ©lectionne Networking only (Fargate)

- Clique sur Next step

 - Nom du cluster : p8-mongodb-cluster-v2

- Laisse les autres paramÃ¨tres par dÃ©faut (VPC, subnets, etc.)

- Clique sur Create

Justification Fargate :

- Pas de gestion de serveur EC2

- ScalabilitÃ© automatique

- IdÃ©al pour un projet Data orientÃ© cloud

## 4.3ï¸ Task Definition MongoDB

Mode pas-Ã -pas :

- Dans la console ECS â†’ Task Definitions â†’ Create new Task Definition

- Choisir Fargate â†’ Next step

- Nom de la Task : p8-mongodb-task

- Task Role : None (ou ecsTaskExecutionRole par dÃ©faut)

- Network Mode : awsvpc

- Container Definitions â†’ Add container

- Container name : mongodb

- Image : mongo:7.0

- Memory Limits : 512 MiB (minimum suffisant pour le projet)

- Port mappings : Container port 27017

Storage and Logging :

- Enable CloudWatch Logs

- Log group : /ecs/mongodb-task-p8

- Stream prefix : mongo

- Region : eu-west-3

Clique sur Add puis Create pour finaliser la Task Definition

Notes :

- Le port 27017 est le port standard MongoDB

- Les logs sont visibles en temps rÃ©el dans CloudWatch

## 4ï¸.4 SÃ©curitÃ© rÃ©seau

Mode pas-Ã -pas :

Aller dans EC2 â†’ Security Groups

CrÃ©er un nouveau Security Group : mongodb-sg

Ajouter une rÃ¨gle entrante :

Type : Custom TCP Rule

Port : 27017

Source : IP de ton PC (x.x.x.x/32)

Associer ce Security Group Ã  la Task ECS lors du lancement

## 4.5ï¸ Lancement de la Task ECS

Mode pas-Ã -pas :

Dans ECS â†’ Clusters â†’ p8-mongodb-cluster-v2

Clique sur Tasks â†’ Run Task

Launch type : Fargate

Cluster VPC : choisir le VPC par dÃ©faut

Subnet : sÃ©lectionner un subnet public

Assign public IP : Enabled

Security group : mongodb-sg

Task Definition : p8-mongodb-task

Clique sur Run Task

ğŸ“Œ Une fois la Task lancÃ©e, tu peux rÃ©cupÃ©rer lâ€™IP publique dans la colonne Public IP pour te connecter depuis MongoDB Compass ou tes scripts Python :

mongodb://<IP_PUBLIQUE_ECS>:27017


## ğŸ“¥ Phase 2 â€” Import des donnÃ©es depuis S3 vers MongoDB ECS

## 5 ğŸ¯ Principe

ğŸ‘‰ Les donnÃ©es ne sont pas copiÃ©es depuis MongoDB local
ğŸ‘‰ Elles sont rÃ©importÃ©es proprement depuis S3, source de vÃ©ritÃ© du projet.

Script utilisÃ© : import_s3_to_aws_ECS.py
RÃ´le du script

Lire le fichier JSON depuis S3

InsÃ©rer les documents dans MongoDB ECS

VÃ©rifier :

- nombre de documents ;

- doublons ;

- valeurs critiques manquantes

```bash
Configuration MongoDB
MONGO_URI_AWS = os.getenv(
    "MONGO_URI_AWS",
    "mongodb://<IP_PUBLIQUE_ECS>:27017"
)
```

â¡ï¸ Le script est exÃ©cutÃ© en local, ce qui est explicitement autorisÃ© par lâ€™Ã©noncÃ©.

Commande dâ€™exÃ©cution
```bash
python import_s3_to_aws_ECS.py
```
RÃ©sultat obtenu
```bash
4950 documents importÃ©s

0 doublon

0 valeur critique manquante
```
DonnÃ©es visibles dans MongoDB Compass

##â± Phase 3 â€” Mesure du temps dâ€™accessibilitÃ© aux donnÃ©es

## 6 ğŸ¯ Objectif

Mesurer le temps rÃ©el dâ€™exÃ©cution dâ€™une requÃªte MongoDB sur une base distante hÃ©bergÃ©e sur AWS.

Principe : 

- Script Python exÃ©cutÃ© en local

- Connexion Ã  MongoDB ECS

- RequÃªte ciblÃ©e :

 - une date ;

 - une station ;

- Mesure via time.perf_counter()

Exemple de mÃ©trique
Temps dâ€™exÃ©cution de la requÃªte : 0.320 secondes


ğŸ‘‰ RÃ©sultat exploitable dans le reporting.

## ğŸ’¾ Phase 4 â€” Sauvegarde de la base MongoDB
## 7 ğŸ¯ Objectif

Mettre en place une stratÃ©gie de sauvegarde cloud fiable et reproductible.

Outil utilisÃ© :
```bash
mongodump
```

Installation locale

Ajout au PATH systÃ¨me Windows

Commande exÃ©cutÃ©e dans le script
```bash
mongodump \
  --uri="mongodb://<IP_PUBLIQUE_ECS>:27017" \
  --archive="mongodb_backup_2026-01-05_14-06-15.gz" \
  --gzip
```

RÃ©sultat
```bash
done dumping p8_greenandcoop_forecast.weather_data (4950 documents)
```

Upload du backup vers S3
```bash
aws s3 cp mongodb_backup_2026-01-05_14-06-15.gz \
s3://p8-meteo/p8-backups/mongodb/
```

Emplacement final
```bash
s3://p8-meteo/p8-backups/mongodb/mongodb_backup_2026-01-05_14-06-15.gz
```

ğŸ“Œ La sauvegarde est :

- horodatÃ©e ;

- externalisÃ©e ;

- restaurable.

## ğŸ“Š Phase 5 â€” Monitoring & logs

## 8 Logs MongoDB

Les logs MongoDB sont centralisÃ©s dans AWS CloudWatch

Les logs comprennent :

- connexions ;

- interruptions ;

- performances ;

- Ã©tat du conteneur

ğŸ‘‰ Cette supervision rÃ©pond aux exigences de surveillance cloud.

âœ… Validation finale

Ã‰lÃ©ment	                 Statut

MongoDB sur ECS	         âœ…
AccÃ¨s distant	           âœ…
Import S3 â†’ MongoDB	     âœ…
Temps dâ€™accessibilitÃ©    âœ…
Sauvegarde S3	           âœ…
Logs & monitoring	       âœ…

âœ… Validation finale

| Exigence du projet                        | Validation  |
|:------------------------------------------|:----------- |
| DÃ©ploiement MongoDB sur AWS ECS           | âœ…         |
| AccÃ¨s distant sÃ©curisÃ©                    | âœ…         |
| Import des donnÃ©es depuis S3 dans MongoDB | âœ…         |
| Mesure du temps dâ€™accÃ¨s                   | âœ…         |
| Sauvegarde cloud dans S3                  | âœ…         |
| Monitoring et logs                        | âœ…         |