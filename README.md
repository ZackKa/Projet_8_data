# README â€” Ã‰tape 1
IntÃ©gration et transformation de donnÃ©es mÃ©tÃ©orologiques (Forecast 2.0)
Projet : GreenAndCoop â€“ Forecast 2.0

RÃ´le : Data Engineer
Objectif de lâ€™Ã©tape 1 :
Mettre en place un premier pipeline permettant de collecter, transformer, tester et stocker des donnÃ©es mÃ©tÃ©orologiques issues de diffÃ©rentes sources dans Amazon S3, dans un format compatible avec une future intÃ©gration dans MongoDB.

## 1. Contexte du projet

Dans le cadre du projet Forecast 2.0, lâ€™entreprise GreenAndCoop souhaite enrichir ses modÃ¨les de prÃ©vision de la demande Ã©lectrique avec de nouvelles sources de donnÃ©es mÃ©tÃ©orologiques, notamment :

Des stations semi-professionnelles du rÃ©seau InfoClimat

Des stations amateurs du rÃ©seau Weather Underground (France et Belgique)

Ces sources prÃ©sentent :

des formats hÃ©tÃ©rogÃ¨nes (JSON, Excel)

des frÃ©quences diffÃ©rentes

des mÃ©tadonnÃ©es variables

Le rÃ´le du Data Engineer est de construire un pipeline fiable permettant de fournir des donnÃ©es propres, cohÃ©rentes et exploitables par les Data Scientists.

## 2. Architecture de lâ€™Ã©tape 1

Vue dâ€™ensemble

```java
Sources mÃ©tÃ©o
   â”‚
   â–¼
Airbyte
   â”‚
   â–¼
Amazon S3 (zone RAW)
   â”‚
   â–¼
Scripts Python (transformation + tests)
   â”‚
   â–¼
Amazon S3 (zone PROCESSED, format MongoDB-ready)
```
Structure S3 utilisÃ©e

```pgsql
s3://p8-meteo/
â”‚
â”œâ”€â”€ p8-data-path/                # DonnÃ©es brutes (Airbyte)
â”‚   â”œâ”€â”€ InfoClimat_data/
â”‚   â”œâ”€â”€ France_data/
â”‚   â””â”€â”€ Belgique_data/
â”‚
â””â”€â”€ p8-processed/                # DonnÃ©es transformÃ©es
    â”œâ”€â”€ weather_mongodb_ready.json
    â””â”€â”€ quality_report.json
```


## 3. Collecte des donnÃ©es (Airbyte)

La collecte est rÃ©alisÃ©e avec Airbyte, qui permet de :

se connecter aux diffÃ©rentes sources mÃ©tÃ©o

uniformiser lâ€™extraction

stocker les donnÃ©es brutes dans Amazon S3

Les donnÃ©es sont exportÃ©es au format JSONL dans un bucket S3.

ğŸ‘‰ Aucune transformation nâ€™est faite dans Airbyte
Toute la logique mÃ©tier est volontairement gÃ©rÃ©e cÃ´tÃ© Python.


### 3.1 Installation et configuration dâ€™Airbyte

PrÃ©requis :

Docker Desktop installÃ© et en fonctionnement

Terminal (PowerShell, CMD ou bash)

Installation Airbyte via Docker

Suivre les Ã©tapes de la documentation officiel:
https://docs.airbyte.com/platform/using-airbyte/getting-started/oss-quickstart

AccÃ©der Ã  Airbyte :
Ouvrir un navigateur â†’ http://localhost:8000


### 3.2 PrÃ©paration AWS

#### 3.2.1 CrÃ©ation dâ€™un bucket S3

Connectez-vous Ã  votre console AWS.

Allez dans S3 â†’ Create bucket

Donnez un nom unique, ex : p8-meteo

Configurez la rÃ©gion (ex : eu-west-3)

Laissez les autres paramÃ¨tres par dÃ©faut â†’ Create bucket


#### 3.2.2 CrÃ©ation dâ€™un utilisateur IAM pour Airbyte

Aller dans IAM â†’ Users â†’ Add user

Nom : airbyte-s3-user

AccÃ¨s programmatique â†’ cochez Programmatic access

Attachez la policy AmazonS3FullAccess

Cliquez sur Create user

RÃ©cupÃ©rez :

AWS_ACCESS_KEY_ID

AWS_SECRET_ACCESS_KEY

âš ï¸ Important : Conservez-les prÃ©cieusement, ne les mettez pas dans Git.


### 3.3 Connexion Airbyte â†’ AWS S3 (Destination)

Dans Airbyte :

Ajouter une destination

Type : Amazon S3

Renseignez :

Access Key ID â†’ AWS_ACCESS_KEY_ID

Secret Access Key â†’ AWS_SECRET_ACCESS_KEY

Bucket Name â†’ p8-meteo

Region â†’ eu-west-3

Testez la connexion â†’ Save


### 3.4 Configuration Airbyte

DÃ©finition des sources et de la destination dans Airbyte

#### 3.4.1 DÃ©finir les sources mÃ©tÃ©o

Dans Airbyte :

Ajouter une source â†’ choisir le connecteur correspondant :

InfoClimat : JSON depuis API ou fichiers bruts

Weather Underground : Excel ou API selon le setup

Renseigner les paramÃ¨tres spÃ©cifiques Ã  chaque source :

Nom de la source (ex : InfoClimat_FR)

Chemin dâ€™accÃ¨s ou URL

FrÃ©quence de synchronisation

Tester la connexion â†’ Save

RÃ©pÃ©tez pour toutes les sources (InfoClimat, France_data, Belgique_data).


#### 3.4.2 DÃ©finir la destination S3

Ajouter une destination â†’ choisir Amazon S3

ParamÃ¨tres Ã  remplir :

AWS Access Key ID â†’ AWS_ACCESS_KEY_ID

AWS Secret Access Key â†’ AWS_SECRET_ACCESS_KEY

Bucket Name â†’ p8-meteo

Region â†’ eu-west-3

Format â†’ JSONL

Tester la connexion â†’ Save


#### 3.4.3 CrÃ©er la connexion (Sync) Airbyte

Aller dans Connections â†’ New connection

SÃ©lectionner :

Source â†’ la source mÃ©tÃ©o dÃ©finie

Destination â†’ Amazon S3

Configurer :

FrÃ©quence â†’ Ex. Every hour ou Manual

Mode de chargement â†’ Overwrite ou Append selon le besoin

Tester â†’ Save â†’ Sync now

Les donnÃ©es brutes de chaque source seront automatiquement stockÃ©es dans S3 (p8-data-path/â€¦) en JSONL, prÃªtes pour la transformation Python.


## 4. Transformation des donnÃ©es (S3 â†’ S3)
Objectif

Transformer les donnÃ©es brutes en documents JSON compatibles MongoDB, avec :

un schÃ©ma commun entre toutes les sources

la conservation maximale des informations

une structure facilement requÃªtable

SchÃ©ma cible (logique)
```json
{
  "source": "weather_underground | infoclimat",
  "station": { ... },
  "timestamp": "ISO-8601",
  "measurements": { ... }
}
```

Points techniques importants
Weather Underground

Les fichiers Excel contenaient une feuille par jour

La date nâ€™est pas conservÃ©e par Airbyte

Les donnÃ©es sont ordonnÃ©es par heure (Time)

ğŸ‘‰ La date est reconstruite en dÃ©tectant le retour Ã  00:xx:xx, ce qui indique un changement de jour.

InfoClimat

Les mÃ©tadonnÃ©es des stations sont extraites et intÃ©grÃ©es

Toutes les mesures disponibles sont conservÃ©es (tempÃ©rature, pression, pluie, neige, vent, etc.)

Les valeurs manquantes sont gÃ©rÃ©es explicitement (None ou 0 selon le cas)



## 5. ContrÃ´le qualitÃ© des donnÃ©es

Un script dÃ©diÃ© permet de mesurer la qualitÃ© des donnÃ©es aprÃ¨s transformation :

VÃ©rifications effectuÃ©es

PrÃ©sence de valeurs manquantes critiques (tempÃ©rature)

DÃ©tection de doublons (station_id + timestamp)

Calcul dâ€™un taux dâ€™erreur global

```yaml
RÃ©sultat obtenu
Total records        : 4950
Valeurs manquantes   : 0
Doublons             : 0
Taux dâ€™erreur        : 0.0 %
```

Ces rÃ©sultats garantissent que les donnÃ©es sont prÃªtes pour une intÃ©gration en base NoSQL.


## 6. PrÃ©requis techniques

Environnement

Windows

Python â‰¥ 3.9

Compte AWS actif

Docker Desktop installÃ© (utilisÃ© dans les Ã©tapes suivantes)


## 7. Configuration AWS

Installation de lâ€™AWS CLI

TÃ©lÃ©charger et installer lâ€™AWS CLI depuis :
https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html

Configuration des credentials

Dans un terminal PowerShell :
```bash
aws configure
```

Renseigner :
```bash
AWS Access Key ID

AWS Secret Access Key

Default region name (ex : eu-west-3)

Default output format : json
```

VÃ©rification
```bash
aws s3 ls
```

Le bucket p8-meteo doit apparaÃ®tre.


## 8. DÃ©pendances Python

requirements.txt
```bash
boto3==1.42.19
python-dateutil==2.9.0
```

Installation

Avec un environnement virtuel (recommandÃ©) :

```bash
pip install -r requirements.txt
```


## 9. ExÃ©cution des scripts

Transformation des donnÃ©es
```bash
python transform_weather_s3.py
```

RÃ©sultat :
```bash
p8-processed/weather_mongodb_ready.json
```

Tests de qualitÃ©
```bash
python data_quality_checks_s3.py
```

RÃ©sultat :
```bash
p8-processed/quality_report.json
```


## 10. Conclusion de lâ€™Ã©tape 1

Ã€ lâ€™issue de cette Ã©tape :

Les donnÃ©es sont centralisÃ©es dans S3

Elles sont nettoyÃ©es, structurÃ©es et enrichies

Leur qualitÃ© est mesurÃ©e et validÃ©e

Le format est directement compatible MongoDB

ğŸ‘‰ Le pipeline est prÃªt pour lâ€™Ã‰tape 2 : intÃ©gration dans MongoDB, mise en place du schÃ©ma et des collections.


# Ã‰TAPE 2 â€” Migration des donnÃ©es vers MongoDB

## 1ğŸ¯ Objectif de lâ€™Ã©tape

Cette Ã©tape consiste Ã  importer les donnÃ©es mÃ©tÃ©orologiques prÃ©alablement transformÃ©es (Ã‰tape 1) depuis Amazon S3 vers une base de donnÃ©es MongoDB, tout en :

respectant un schÃ©ma commun pour toutes les sources,

assurant la qualitÃ© et lâ€™intÃ©gritÃ© des donnÃ©es post-migration,

mettant en place des contrÃ´les automatiques,

documentant clairement le processus.


## 2ğŸ§± Architecture retenue

Source des donnÃ©es :
Amazon S3
s3://p8-meteo/p8-processed/weather_mongodb_ready.json

Base de donnÃ©es :
MongoDB en local (Docker / MongoDB Community)

Nom de la base :
p8_greenandcoop_forecast

Collection unique :
weather_data

ğŸ‘‰ Le choix dâ€™une seule collection permet :

dâ€™unifier les requÃªtes,

de faciliter lâ€™agrÃ©gation multi-sources,

de garantir un schÃ©ma homogÃ¨ne.


## 3ğŸ“„ Format des donnÃ©es importÃ©es

Les donnÃ©es sont stockÃ©es dans un fichier JSON compatible MongoDB, contenant une liste de documents standardisÃ©s.

Structure logique dâ€™un document :
{
  "source": "weather_underground | infoclimat",
  "station": {
    "station_id": "string",
    "name": "string",
    "latitude": float,
    "longitude": float,
    "elevation": int
  },
  "timestamp": "ISO-8601",
  "measurements": {
    "temperature_c": float,
    "humidity_pct": float,
    "pressure_hpa": float,
    "wind_speed": float,
    "wind_gust": float,
    "precip_mm": float
  }
}


Ce schÃ©ma est identique pour toutes les sources, conformÃ©ment aux exigences du projet.


## 4ğŸ” Processus suivi (logigramme)

Le processus a Ã©tÃ© formalisÃ© sous forme de logigramme visuel, basÃ© sur les Ã©tapes suivantes :

- DÃ©finir sources mÃ©tÃ©o dans Airbyte (Ã©tape 1)

- DÃ©finir destination S3 dans Airbyte (Ã©tape 1)

- CrÃ©er la connexion (Sync) Airbyte (Ã©tape 1)

- Airbyte collecte les donnÃ©es â†’ Stockage dans S3 (Ã©tape 1)

- Lecture du fichier JSON depuis S3

- Chargement des documents en mÃ©moire

- Connexion Ã  MongoDB

- Insertion des documents dans la collection

- VÃ©rifications post-import :

nombre total de documents,

doublons,

valeurs manquantes sur champs critiques

- Affichage des rÃ©sultats en console


## 5 ğŸ§ª ContrÃ´les qualitÃ© post-migration

AprÃ¨s lâ€™import, le script exÃ©cute automatiquement plusieurs contrÃ´les :

âœ”ï¸ Indicateurs mesurÃ©s

Nombre total de documents importÃ©s

Nombre de doublons (station_id + timestamp)

Nombre de documents sans :

tempÃ©rature

humiditÃ©

pression

âœ”ï¸ RÃ©sultat obtenu
Total documents en base : 4950
Nombre de doublons dÃ©tectÃ©s : 0
Documents sans tempÃ©rature : 0
Documents sans humiditÃ© : 0
Documents sans pression : 0


ğŸ‘‰ Ces rÃ©sultats confirment :

lâ€™intÃ©gritÃ© du schÃ©ma,

lâ€™absence de perte de donnÃ©es,

une migration fiable.


## 6 ğŸ Script utilisÃ©

Un script Python unique est utilisÃ© pour :

rÃ©cupÃ©rer le fichier depuis S3,

importer les donnÃ©es dans MongoDB,

exÃ©cuter les contrÃ´les qualitÃ©,

afficher les rÃ©sultats via des print() explicites.

Script principal
import_s3_to_mongodb.py


## 7 â–¶ï¸ ExÃ©cution du script

### 1ï¸âƒ£ PrÃ©-requis

MongoDB lancÃ© en local (Docker ou service local)

AccÃ¨s AWS configurÃ©

Environnement Python actif

ğŸ“¦ DÃ©pendances Python

Installer pymongo avec la version dans requirements.txt

Le fichier requirements.txt inclut notamment :

boto3==1.42.19
python-dateutil==2.9.0
pymongo==4.15.4


ğŸ‘‰ pymongo est utilisÃ© pour la communication avec MongoDB
ğŸ‘‰ boto3 permet lâ€™accÃ¨s aux objets stockÃ©s sur S3

### 2ï¸âƒ£ Commande dâ€™exÃ©cution
python import_s3_to_mongodb.py

### 3ï¸âƒ£ RÃ©sultat attendu en console
RÃ©cupÃ©ration du fichier depuis S3...
Nombre de documents Ã  importer : 4950
Documents importÃ©s avec succÃ¨s : 4950

--- VÃ©rification post-import ---
Total documents en base : 4950
Nombre de doublons dÃ©tectÃ©s : 0
Documents sans tempÃ©rature : 0
Documents sans humiditÃ© : 0
Documents sans pression : 0

--- Import terminÃ© ---


## 8 ğŸ” Visualisation des donnÃ©es

Les donnÃ©es peuvent Ãªtre visualisÃ©es avec MongoDB Compass :

Base : p8_greenandcoop_forecast

Collection : weather_data

RÃ©partition observÃ©e :

Infoclimat : 1143 documents

Weather Underground (France + Belgique) : 3807 documents


# Ã‰TAPE 3

Conteneurisation de la migration avec Docker

## 1 ğŸ¯ Objectif de lâ€™Ã©tape 3

Lâ€™objectif de cette Ã©tape est de conteneuriser la migration des donnÃ©es mÃ©tÃ©o depuis Amazon S3 vers MongoDB, afin de :

- garantir la reproductibilitÃ© de lâ€™environnement,

- isoler les composants (base de donnÃ©es / script de migration),

- persister les donnÃ©es via un volume Docker,

- dÃ©montrer une migration automatisÃ©e et fiable.


## 2 ğŸ—ï¸ Architecture mise en place

- 1 conteneur MongoDB
  - Image officielle mongo:7.0
  - DonnÃ©es persistÃ©es via un volume Docker

- 1 conteneur Python
  - ExÃ©cute un script de migration
  - TÃ©lÃ©charge les donnÃ©es depuis S3
  - InsÃ¨re les documents dans MongoDB
  - Effectue des contrÃ´les qualitÃ© post-import

Les deux conteneurs communiquent via le rÃ©seau Docker Compose par dÃ©faut.


## 3 ğŸ“ Structure du projet (Ã©tape 3)

```bash
.
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â”œâ”€â”€ import_s3_to_mongodb_conteneur.py
```

## 4 âš™ï¸ Configuration des variables dâ€™environnement

Le fichier .env (non versionnÃ©) contient :

```env
AWS_ACCESS_KEY_ID=************
AWS_SECRET_ACCESS_KEY=************
AWS_DEFAULT_REGION=eu-west-3

MONGO_URI=mongodb://mongodb:27017
```

- Les credentials AWS permettent lâ€™accÃ¨s au bucket S3

- mongodb correspond au nom du service Docker MongoDB


## 5 ğŸ³ docker-compose.yml (rÃ©sumÃ©)

- MongoDB exposÃ© sur le port local 27021

- Volume Docker pour persister les donnÃ©es

- Conteneur Python dÃ©pendant de MongoDB

MongoDB reste accessible depuis lâ€™hÃ´te via MongoDB Compass :

```bash
mongodb://localhost:27021
```

## 6 ğŸ“¦ Volume Docker

Un volume nommÃ© est utilisÃ© :

```bash
projet8_projet_8_mongo_data
```

Il garantit que les donnÃ©es MongoDB sont conservÃ©es mÃªme aprÃ¨s :

```bash
docker compose down
```

## 7 ğŸ§  Script de migration

Le script import_s3_to_mongodb_conteneur.py effectue :

- 1) Connexion Ã  Amazon S3

- 2) TÃ©lÃ©chargement du fichier JSON final :

```bash
p8-meteo/p8-processed/weather_mongodb_ready.json
```

- 3) Insertion des documents dans MongoDB

- 4) ContrÃ´les qualitÃ© post-import :
  - Nombre total de documents
  - Doublons (station_id + timestamp)
  - champs critiques manquants (tempÃ©rature, humiditÃ©, pression)


## 8 â–¶ï¸ Commandes Ã  exÃ©cuter
ğŸ”¹ Build + lancement complet initial
```bash
docker compose up --build
```
ğŸ”¹ Lancement sans rebuild
```bash
docker compose up
```
ğŸ”¹ ArrÃªt des services
```bash
docker compose down
```
ğŸ”¹ VÃ©rifier les volumes
```bash
docker volume ls
```
ğŸ”¹ VÃ©rifier les conteneurs
```bash
docker ps -a
```
ğŸ”¹ Inspecter un volume en particulier :
```bash
docker volume inspect projet_8_mongo_data
```

## 9 ğŸ” VÃ©rifications attendues

Logs affichant :

```bash
Documents importÃ©s avec succÃ¨s : 4950
```

MongoDB Compass :

- Base : p8_greenandcoop_forecast

- Collection : weather_data

- 4950 documents prÃ©sents

DonnÃ©es toujours prÃ©sentes aprÃ¨s redÃ©marrage


## 10 âœ… RÃ©sultat

Migration automatisÃ©e et reproductible

Environnement isolÃ© via Docker

DonnÃ©es persistÃ©es

QualitÃ© des donnÃ©es contrÃ´lÃ©e

ğŸ‘‰ Cette Ã©tape valide la conteneurisation complÃ¨te de la chaÃ®ne de migration.